{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a451b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import jieba,re,os,pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset,DataLoader, TensorDataset\n",
    "import torch.utils.data as Data\n",
    "import random\n",
    "import math\n",
    "import time,re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f48e3e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "#参数\n",
    "# Transformer Parameters\n",
    "d_model = 512  # Embedding Size\n",
    "d_ff = 2048 # FeedForward dimension\n",
    "n_layers = 6  # number of Encoder of Decoder Layer\n",
    "n_heads = 8  # number of heads in Multi-Head Attention\n",
    "d_k = d_v = d_model//n_heads  # dimension of K(=Q), V #Q 与 K 的维度必须相等\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "BATCH_SIZE = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f004f94",
   "metadata": {},
   "source": [
    "## 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36ff770d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The fewer hours he has to spend laboring , and the more hours he is free to play , the better .\n"
     ]
    }
   ],
   "source": [
    "def add_space_before_punctuation(text):\n",
    "    \"\"\"\n",
    "    在文本中的标点符号前添加一个空格。\n",
    "    参数:\n",
    "    text (str): 要处理的文本字符串。\n",
    "    返回:\n",
    "    str: 在标点符号前添加了空格的文本字符串。\n",
    "    \"\"\"\n",
    "    # 扩展正则表达式以匹配各种标点符号，包括单引号和双引号\n",
    "    pattern = r'([,.:;!?()\\'\"])'\n",
    "    # 使用 re.sub 方法替换文本中的标点符号\n",
    "    # r' \\1' 表示在匹配到的标点符号前添加一个空格\n",
    "    # \\1 是一个反向引用，指代第一个括号内匹配的内容，即标点符号本身\n",
    "    spaced_text = re.sub(pattern, r' \\1', text)\n",
    "    # 返回处理后的文本\n",
    "    return spaced_text\n",
    "\n",
    "text = \"The fewer hours he has to spend laboring, and the more hours he is free to play, the better.\"\n",
    "result = add_space_before_punctuation(text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "66070665",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_deal_train_data(file_path=\"./data/en_ch.txt\",num=200): #导入数据 \n",
    "    # 使用 read_csv 函数读取文件，指定制表符为分隔符，不读取标题行  \n",
    "    data = pd.read_csv(file_path, sep='\\t', header=None, error_bad_lines=False)#on_bad_lines='skip'  \n",
    "    # 互换第一列和第二列  \n",
    "    data[[0, 1]] = data[[1, 0]].values  \n",
    "    # 初始化空列表，用于存放符合条件的数据  \n",
    "    filtered_chinese = []  \n",
    "    filtered_english = []  \n",
    "    \n",
    "    for index, row in data.iterrows():  \n",
    "        X = row[0]  # 中文  \n",
    "        Y = row[1]  # 英文  \n",
    "        \n",
    "        # 检查X是否是有效的字符串，避免空值或NaN值导致的问题  \n",
    "        if not isinstance(X, str) or re.search(r'<.*?>', X):  \n",
    "            continue  # 如果X无效，则跳过这一行  \n",
    "        \n",
    "        # 检查中文部分是否包含英文字母  \n",
    "        if re.search(r'[a-zA-Z]', X):  \n",
    "            continue  # 如果X包含英文字母，则跳过这一行\n",
    "    \n",
    "        # 检查中文中是否包含特殊符号《、》、（、）、- 等    \n",
    "        if re.search(r'[《》（）-]', X):\n",
    "            continue  # 如果 X 包含特殊符号，则跳过这一行\n",
    "        \n",
    "        # 检查Y是否是有效的字符串  \n",
    "        if not isinstance(Y, str) or len(Y) <= 1:  \n",
    "            continue  # 如果Y无效，则跳过这一行  \n",
    "\n",
    "        # 因为X和Y都是有效的，可以进行处理  \n",
    "        filtered_chinese.append(str(X))  \n",
    "        #规则化英语\n",
    "        filtered_english.append(add_space_before_punctuation(str(Y)).lower())\n",
    "\n",
    "        if len(filtered_english)>num:\n",
    "            break   \n",
    "    return filtered_chinese, filtered_english\n",
    "chinese_sentences,english_sentences=read_deal_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0475695e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 中文句子列表\n",
    "chinese_sentences = [\n",
    "    \"你今天晚上有什么计划吗？\",\n",
    "    \"我喜欢在周末去公园散步。\",\n",
    "    \"这家餐厅的菜很美味。\",\n",
    "    \"我们明天需要完成这个项目。\",\n",
    "    \"你能帮我查一下这本书的价格吗？\",\n",
    "    \"昨天的电影真是太有趣了。\",\n",
    "    \"他正在学习如何编程。\",\n",
    "    \"你知道最近的天气预报吗？\",\n",
    "    \"我们计划下个月去旅行。\",\n",
    "    \"她在音乐会上表演得非常出色。\"\n",
    "]\n",
    "\n",
    "# 英文句子列表\n",
    "english_sentences = [\n",
    "    \"Do you have any plans for tonight?\",\n",
    "    \"I enjoy taking walks in the park on weekends.\",\n",
    "    \"The food at this restaurant is delicious.\",\n",
    "    \"We need to finish this project by tomorrow.\",\n",
    "    \"Can you help me check the price of this book?\",\n",
    "    \"The movie yesterday was really interesting.\",\n",
    "    \"He is learning how to code.\",\n",
    "    \"Do you know the latest weather forecast?\",\n",
    "    \"We plan to go on a trip next month.\",\n",
    "    \"She performed exceptionally well at the concert.\"\n",
    "]\n",
    "english_sentences=[add_space_before_punctuation(str(Y)).lower() for Y in english_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "645c5aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\qiqi\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.578 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "#分词\n",
    "def tokenize_chinese(sentence):#分词\n",
    "    return list(jieba.cut(sentence))\n",
    "tokenized_chinese = [tokenize_chinese(sentence) for sentence in chinese_sentences]\n",
    "tokenized_english = [sentence.split() for sentence in english_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a72bf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据填充-不填<PAD>\n",
    "padded_english = [ ['<start>'] + tokens + ['<end>'] for tokens in tokenized_english ] \n",
    "padded_chinese = [ ['<start>'] + tokens + ['<end>'] for tokens in tokenized_chinese ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a09c85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#生成词表\n",
    "chinese_vocab = {'<pad>': 0 ,'<start>': 1, '<end>': 2}#中文\n",
    "for sentence in padded_chinese:\n",
    "    for token in sentence:\n",
    "        if token not in chinese_vocab:\n",
    "            chinese_vocab[token] = len(chinese_vocab)\n",
    "#保存中文字典\n",
    "with open('./vocab/Transformer_chinese_vocab.pkl', 'wb') as f:  \n",
    "    pickle.dump(chinese_vocab, f)\n",
    "tgt_vocab_size=len(chinese_vocab)\n",
    "\n",
    "english_vocab = {'<pad>': 0 ,'<start>': 1, '<end>': 2} #英文\n",
    "for sentence in padded_english:\n",
    "    for token in sentence:\n",
    "        if token not in english_vocab:\n",
    "            english_vocab[token] = len(english_vocab)\n",
    "src_vocab_size=len(english_vocab)\n",
    "#保存英文字典\n",
    "with open('./vocab/Transformer_english_vocab.pkl', 'wb') as f:  \n",
    "    pickle.dump(english_vocab, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9411c301",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed_chinese = [[chinese_vocab[token] for token in sentence] for sentence in padded_chinese]\n",
    "indexed_english = [[english_vocab[token] for token in sentence] for sentence in padded_english]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60088b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, indexed_english, indexed_chinese,device=device):\n",
    "        self.indexed_english = indexed_english\n",
    "        self.indexed_chinese = indexed_chinese\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indexed_english)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.indexed_english[idx], self.indexed_chinese[idx]\n",
    "    \n",
    "    def batch_data_process(self,batch_datas,pad=0,max_len=128):#按批次填充，<PAD>=0，默认\n",
    "        en_index, ch_index = [], []\n",
    "\n",
    "        for en, ch in batch_datas:\n",
    "            # 截断英文数据，并填充至 max_len\n",
    "            if len(en) > max_len:\n",
    "                en = en[:max_len]\n",
    "            else:\n",
    "                en = en + [pad] * (max_len - len(en))\n",
    "\n",
    "            # 截断中文数据，并填充至 max_len\n",
    "            if len(ch) > max_len:\n",
    "                ch = ch[:max_len]\n",
    "            else:\n",
    "                ch = ch + [pad] * (max_len - len(ch))\n",
    "\n",
    "            en_index.append(en)\n",
    "            ch_index.append(ch)\n",
    "\n",
    "        # 转换为PyTorch张量并指定设备\n",
    "        en_index = torch.tensor(en_index, device=device)\n",
    "        ch_index = torch.tensor(ch_index, device=device)\n",
    "        return en_index,ch_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b72ce16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建 Dataset\n",
    "dataset = TranslationDataset(indexed_english, indexed_chinese)\n",
    "# 创建 DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=dataset.batch_data_process)"
   ]
  },
  {
   "attachments": {
    "image-2.png": {
     "image/png": "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"
    },
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "61432ba6",
   "metadata": {},
   "source": [
    "## Positional Encoding\n",
    "![image-2.png](attachment:image-2.png)\n",
    "![image.png](attachment:image.png)\n",
    "div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "通过一个具体的例子来解释 `div_term` 的计算过程。假设 `d_model` 设置为 8，那么以下代码：\n",
    "\n",
    "```python\n",
    "div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "```\n",
    "\n",
    "可以分解为以下步骤：\n",
    "\n",
    "1. **生成范围**：\n",
    "   ```python\n",
    "   torch.arange(0, d_model, 2).float()\n",
    "   ```\n",
    "   生成从 `0` 到 `d_model-1` 的偶数序列。对于 `d_model=8`，生成的序列是：\n",
    "   ```python\n",
    "   tensor([0., 2., 4., 6.])\n",
    "   ```\n",
    "\n",
    "2. **计算缩放因子**：\n",
    "   ```python\n",
    "   -math.log(10000.0) / d_model\n",
    "   ```\n",
    "   计算常数项 `-math.log(10000.0) / d_model`。对于 `d_model=8`，这个值是：\n",
    "   ```python\n",
    "   -math.log(10000.0) / 8 ≈ -9.21034 / 8 ≈ -1.15129\n",
    "   ```\n",
    "\n",
    "3. **乘法运算**：\n",
    "   ```python\n",
    "   torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model)\n",
    "   ```\n",
    "   将之前生成的偶数序列乘以缩放因子。计算结果是：\n",
    "   ```python\n",
    "   tensor([0.0 * -1.15129, 2.0 * -1.15129, 4.0 * -1.15129, 6.0 * -1.15129])\n",
    "   tensor([0.0, -2.30258, -4.60517, -6.90776])\n",
    "   ```\n",
    "\n",
    "4. **计算指数**：\n",
    "   ```python\n",
    "   torch.exp(tensor([0.0, -2.30258, -4.60517, -6.90776]))\n",
    "   ```\n",
    "   对结果应用指数函数。计算得到：\n",
    "   ```python\n",
    "   tensor([1.0, 0.1, 0.01, 0.001])\n",
    "   ```\n",
    "\n",
    "### 示例代码\n",
    "\n",
    "```python\n",
    "import torch\n",
    "import math\n",
    "\n",
    "d_model = 8\n",
    "div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "print(div_term)\n",
    "```\n",
    "\n",
    "### 输出\n",
    "\n",
    "```\n",
    "tensor([1.0000e+00, 1.0000e-01, 1.0000e-02, 1.0000e-03])\n",
    "```\n",
    "\n",
    "### 解释\n",
    "\n",
    "- **`torch.arange(0, d_model, 2).float()`**：生成的偶数序列 `[0, 2, 4, 6]`。\n",
    "- **`-math.log(10000.0) / d_model`**：常数项 `-1.15129` 用于调整缩放因子。\n",
    "- **乘法运算**：得到 `[0, -2.30258, -4.60517, -6.90776]`。\n",
    "- **`torch.exp()`**：对结果应用指数函数，得到 `[1.0, 0.1, 0.01, 0.001]`，这些是不同频率的缩放因子，用于位置编码。\n",
    "\n",
    "这些缩放因子 (`div_term`) 用于调整正弦和余弦函数的频率，以确保每个维度的编码具有不同的频率，使得每个位置的编码都是唯一的。\n",
    "\n",
    "\n",
    "`torch.arange(0, d_model, 2)` 生成的是一个从 0 到 `d_model-1`（步长为 2）的偶数序列，用于计算 `div_term`。具体来说，这个序列的每个元素表示计算位置编码时需要的不同频率的幂次。\n",
    "\n",
    "让我们逐步解释 Transformer 论文中的位置编码公式，并将其与代码中的计算方法对应起来：\n",
    "\n",
    "### Transformer 论文中的公式\n",
    "\n",
    "在 Transformer 论文中，位置编码的公式为：\n",
    "\n",
    "$$\n",
    "\\text{PE}(pos, 2i) = \\sin\\left(\\frac{pos}{10000^{2i/d\\_model}}\\right)\n",
    "$$\n",
    "$$\n",
    "\\text{PE}(pos, 2i+1) = \\cos\\left(\\frac{pos}{10000^{2i/d\\_model}}\\right)\n",
    "$$\n",
    "- `pos` 是位置索引。\n",
    "- `2i` 和 `2i+1` 表示编码的维度（偶数维度和奇数维度）。\n",
    "\n",
    "### 代码中的实现\n",
    "\n",
    "在代码中，`div_term` 的计算是：\n",
    "\n",
    "```python\n",
    "div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "```\n",
    "\n",
    "这实际上是对 Transformer 论文公式的一个等效实现：\n",
    "\n",
    "1. **指数部分**：`10000^{2i/d_model}` 可以转换为对数形式，`exp` 函数用于计算指数。\n",
    "$$\n",
    "\\text{PE}(pos, 2i) = \\sin\\left(\\frac{pos}{10000^{\\frac{2i}{d\\_model}}}\\right)\n",
    "$$\n",
    "2. **计算 `div_term`**：\n",
    "\n",
    "   \\[\n",
    "   \\text{div\\_term}[i] = e^{(2i/d\\_model) \\cdot \\log(10000)}\n",
    "   \\]\n",
    "\n",
    "   这里 `torch.arange(0, d_model, 2)` 生成了偶数序列 `0, 2, 4, ..., d_model-2`，对应 `2i`。\n",
    "\n",
    "   `-math.log(10000.0) / d_model` 是 `\\log(10000)` 的负值，再除以 `d_model`，用于计算缩放因子。这样 `exp` 的计算会产生与 `10000^{2i/d_model}` 对应的值。\n",
    "\n",
    "### 总结\n",
    "\n",
    "- `torch.arange(0, d_model, 2)` 生成偶数索引，这些索引用于计算不同频率的缩放因子。\n",
    "- `div_term` 是用 `exp` 函数计算的，以实现和论文中相同的频率计算方式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cbc9022f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=128):\n",
    "        \"\"\"\n",
    "        初始化PositionalEncoding模块。\n",
    "        :param d_model: 嵌入向量的维度。\n",
    "        :param dropout: Dropout层的丢弃概率，用于防止过拟合。\n",
    "        :param max_len: 序列的最大长度。\n",
    "        \"\"\"\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        # 定义Dropout层\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        # 创建位置编码矩阵，大小为 (max_len, d_model)\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        # 生成位置索引 [0, 1, 2, ..., max_len-1] 并扩展为列向量\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        \"\"\"\n",
    "        tensor([0.0, 1.0, 2.0, 3.0])\n",
    "        .unsqueeze(1)后\n",
    "        tensor([[0.0],\n",
    "            [1.0],\n",
    "            [2.0],\n",
    "            [3.0]])\n",
    "        \"\"\"\n",
    "        # 计算位置编码中的“缩放因子” (div_term)，用于生成不同频率的正弦和余弦函数\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        # 对偶数维度应用正弦函数\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        # 对奇数维度应用余弦函数\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        # 将pe的形状调整为 (1, max_len, d_model) 并进行转置\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        \n",
    "        # 注册pe为模型的缓冲区，以便在保存和加载模型时保持其值\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        前向传播函数。\n",
    "        :param x: 输入张量，形状为 (seq_len, batch_size, d_model)。\n",
    "        :return: 加入位置编码后的张量。\n",
    "        \"\"\"\n",
    "        # x的形状为 (seq_len, batch_size, d_model)，\n",
    "        # self.pe的形状为 (1, max_len, d_model)，\n",
    "        # 所以将self.pe裁剪到与x的序列长度相同\n",
    "        x = x + self.pe[:x.size(0), :]# max_len ！= seq_len\n",
    "        \n",
    "        # 应用Dropout层\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69ffeb6",
   "metadata": {},
   "source": [
    "## Pad Mask\n",
    "\n",
    "让我们详细演示如何生成 `pad_attn_mask`，使用你提供的 `seq_q` 和 `seq_k`。下面的代码展示了如何从这两个序列创建 PAD 掩码，并将其扩展到每个查询步骤。\n",
    "\n",
    "### 输入数据\n",
    "\n",
    "```python\n",
    "import torch\n",
    "\n",
    "# Query sequences and Key sequences\n",
    "seq_q = torch.tensor([\n",
    "    [1, 2, 3, 0, 0],  # Query sequence for batch 1\n",
    "    [2, 100, 3, 4, 0]   # Query sequence for batch 2\n",
    "])\n",
    "\n",
    "seq_k = torch.tensor([\n",
    "    [1, 2, 3, 0, 0],  # Key sequence for batch 1\n",
    "    [2, 100, 3, 4, 0]    # Key sequence for batch 2\n",
    "])\n",
    "```\n",
    "\n",
    "### 步骤 1: 创建 PAD 掩码\n",
    "\n",
    "首先，我们需要标记 `seq_k` 中的 PAD 位置：\n",
    "\n",
    "```python\n",
    "pad_attn_mask = seq_k.data.eq(0).unsqueeze(1)\n",
    "```\n",
    "\n",
    "解释：\n",
    "- `seq_k.data.eq(0)`：生成一个布尔掩码，标记值为 `0` 的位置为 `True`，其他位置为 `False`。\n",
    "- `unsqueeze(1)`：在第二维添加一个维度，将掩码的形状从 `[batch_size, seq_len_k]` 变为 `[batch_size, 1, seq_len_k]`。\n",
    "\n",
    "生成的 `pad_attn_mask` 是：\n",
    "\n",
    "```python\n",
    "pad_attn_mask = torch.tensor([\n",
    "    [[False, False, False, True, True]],  # Mask for batch 1\n",
    "    [[False, False, False, True, True]]   # Mask for batch 2\n",
    "])\n",
    "```\n",
    "\n",
    "### 步骤 2: 扩展掩码\n",
    "\n",
    "然后，我们将掩码扩展到查询序列的每一个时间步：\n",
    "\n",
    "```python\n",
    "batch_size, len_q = seq_q.size()\n",
    "len_k = seq_k.size(1)\n",
    "pad_attn_mask = pad_attn_mask.expand(batch_size, len_q, len_k)\n",
    "```\n",
    "\n",
    "解释：\n",
    "- `expand(batch_size, len_q, len_k)`：将掩码的形状从 `[batch_size, 1, len_k]` 扩展到 `[batch_size, len_q, len_k]`。\n",
    "\n",
    "扩展后的 `pad_attn_mask` 是：\n",
    "\n",
    "```python\n",
    "pad_attn_mask = torch.tensor([\n",
    "    [[False, False, False, True, True],  # Expanded mask for query step 1\n",
    "     [False, False, False, True, True],  # Expanded mask for query step 2\n",
    "     [False, False, False, True, True],  # Expanded mask for query step 3\n",
    "     [False, False, False, True, True],  # Expanded mask for query step 4\n",
    "     [False, False, False, True, True]], # Expanded mask for query step 5\n",
    "    [[False, False, False, True, True],  # Expanded mask for query step 1\n",
    "     [False, False, False, True, True],  # Expanded mask for query step 2\n",
    "     [False, False, False, True, True],  # Expanded mask for query step 3\n",
    "     [False, False, False, True, True],  # Expanded mask for query step 4\n",
    "     [False, False, False, True, True]]  # Expanded mask for query step 5\n",
    "])\n",
    "```\n",
    "\n",
    "### 总结\n",
    "\n",
    "`pad_attn_mask` 的形状是 `[2, 5, 5]`，其中 `2` 是批量大小，`5` 是序列长度。掩码的每一层 `[False, False, False, True, True]` 对应于 `seq_k` 中的 PAD 位置，确保在计算注意力时，PAD 位置不会对结果产生影响。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a0a08be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attn_pad_mask(seq_q, seq_k):  \n",
    "    '''  \n",
    "    seq_q: [batch_size, seq_len]  # 查询序列，形状为(batch_size, seq_len)  \n",
    "    seq_k: [batch_size, seq_len]  # 键序列，形状为(batch_size, seq_len)  \n",
    "    seq_len可以是源序列的长度(source length)或目标序列的长度(target length)  \n",
    "    seq_q中的seq_len和seq_k中的seq_len可能不相等  \n",
    "    '''  \n",
    "    batch_size, len_q = seq_q.size()  # 获取查询序列的batch大小和长度  \n",
    "    batch_size, len_k = seq_k.size()  # 获取键序列的batch大小和长度  \n",
    "    \n",
    "    # eq(zero)是PAD标记，通常PAD标记的值为0  \n",
    "    pad_attn_mask = seq_k.data.eq(0).unsqueeze(1)  # 创建一个掩码，标记键序列中PAD的位置  \n",
    "    # 这里的pad_attn_mask的形状为[batch_size, 1, len_k]，其中True表示被掩蔽的位置  \n",
    "    \n",
    "    # 扩展掩码，使其适用于查询序列的每一个时间步  \n",
    "    return pad_attn_mask.expand(batch_size, len_q, len_k)  # 返回的掩码形状为[batch_size, len_q, len_k]  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9208e82f",
   "metadata": {},
   "source": [
    "## Subsequence Mask(Decoder )\n",
    "假设我们有一个批次的序列数据，`batch_size` 为 2，`tgt_len` 为 4。也就是说，我们有 2 个序列，每个序列的长度都是 4。我们用一个简单的示例来说明如何生成掩码。\n",
    "### 输出\n",
    "\n",
    "对于 `batch_size = 2` 和 `tgt_len = 4`，生成的掩码将是一个形状为 `[2, 4, 4]` 的张量。掩码的每个矩阵都会是一个上三角矩阵，其形状如下：\n",
    "\n",
    "```python\n",
    "tensor([[[0, 1, 1, 1],\n",
    "         [0, 0, 1, 1],\n",
    "         [0, 0, 0, 1],\n",
    "         [0, 0, 0, 0]],\n",
    "\n",
    "        [[0, 1, 1, 1],\n",
    "         [0, 0, 1, 1],\n",
    "         [0, 0, 0, 1],\n",
    "         [0, 0, 0, 0]]], dtype=torch.uint8)\n",
    "```\n",
    "\n",
    "### 解释\n",
    "\n",
    "这个掩码的每一行表示当前标记能够关注的内容：\n",
    "- 第一个标记（索引 0）可以关注到所有其他标记（索引 1, 2, 3），因此掩码的第一行是 `[0, 1, 1, 1]`。\n",
    "- 第二个标记（索引 1）只能关注到标记 1 及其后面的标记（索引 2, 3），因此掩码的第二行是 `[0, 0, 1, 1]`。\n",
    "- 第三个标记（索引 2）只能关注到标记 2 及其后面的标记（索引 3），因此掩码的第三行是 `[0, 0, 0, 1]`。\n",
    "- 第四个标记（索引 3）不能关注任何标记，因此掩码的第四行是 `[0, 0, 0, 0]`。\n",
    "\n",
    "这个掩码确保了模型在生成或预测时，只能关注当前和过去的标记，而不能看到未来的标记，从而模拟自回归模型的训练和推理过程。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "154acdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attn_subsequence_mask(seq):\n",
    "    '''\n",
    "    生成一个掩码，防止模型在序列中关注未来的标记。\n",
    "    参数:\n",
    "        seq (Tensor): 一个形状为 [batch_size, tgt_len] 的张量，其中 batch_size 是批次中的序列数，\n",
    "                      tgt_len 是每个序列的长度。\n",
    "    返回:\n",
    "        Tensor: 形状为 [batch_size, tgt_len, tgt_len] 的二进制掩码，其中每个批次中的矩阵都具有上三角结构，\n",
    "                上三角部分填充 1（阻止未来标记），其余部分填充 0（允许的标记）。\n",
    "    '''\n",
    "    # 根据目标序列长度确定掩码的形状\n",
    "    # 每个序列的掩码形状为 [tgt_len, tgt_len]\n",
    "    attn_shape = [seq.size(0), seq.size(1), seq.size(1)]\n",
    "    # 创建一个上三角矩阵，主对角线上的 1 表示可以关注的标记，上三角部分的 1 表示阻止关注的未来标记\n",
    "    subsequence_mask = np.triu(np.ones(attn_shape), k=1)  # 上三角矩阵，主对角线以上的部分为 1\n",
    "    # 将 numpy 数组转换为 PyTorch 张量，并确保其数据类型为 byte\n",
    "    subsequence_mask = torch.from_numpy(subsequence_mask).byte()  # 转换为 PyTorch 张量，数据类型为 byte\n",
    "    return subsequence_mask  # 返回形状为 [batch_size, tgt_len, tgt_len] 的掩码张量"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6819e6",
   "metadata": {},
   "source": [
    "## Scaled_Dot_Product_Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63e74f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaledDotProductAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        初始化 ScaledDotProductAttention 类的实例。\n",
    "        '''\n",
    "        super(ScaledDotProductAttention, self).__init__()\n",
    "\n",
    "    def forward(self, Q, K, V, attn_mask):\n",
    "        '''\n",
    "        前向传播函数，计算缩放点积注意力机制。\n",
    "        \n",
    "        参数:\n",
    "            Q (Tensor): 查询张量，形状为 [batch_size, n_heads, len_q, d_k]。\n",
    "            K (Tensor): 键张量，形状为 [batch_size, n_heads, len_k, d_k]。\n",
    "            V (Tensor): 值张量，形状为 [batch_size, n_heads, len_v(=len_k), d_v]。\n",
    "            attn_mask (Tensor): 注意力掩码，形状为 [batch_size, n_heads, seq_len, seq_len]。\n",
    "            \n",
    "        返回:\n",
    "            context (Tensor): 上下文向量，形状为 [batch_size, n_heads, len_q, d_v]。\n",
    "            attn (Tensor): 注意力权重，形状为 [batch_size, n_heads, len_q, len_k]。\n",
    "        '''\n",
    "        # 计算点积得分，得分的形状为 [batch_size, n_heads, len_q, len_k]\n",
    "        # Q 和 K 的维度 d_k 需要被缩放，以避免点积结果过大\n",
    "        # K.transpose(-1, -2) 的形状为 [batch_size, n_heads, d_k, len_k]\n",
    "        # Q:[batch_size, n_heads, len_q, d_k] * [batch_size, n_heads, d_k, len_k]\n",
    "        #最后两个维度矩阵乘法\n",
    "        scores = torch.matmul(Q, K.transpose(-1, -2)) / np.sqrt(d_k)\n",
    "        # 使用掩码填充得分矩阵中的无效位置，填充值为 -1e9，确保这些位置在 softmax 计算时不会被选中\n",
    "        scores.masked_fill_(attn_mask, -1e9)#[batch_size, n_heads, len_q, len_k]\n",
    "        # 对得分应用 softmax，计算注意力权重\n",
    "        attn = nn.Softmax(dim=-1)(scores)#[batch_size, n_heads, len_q, len_k]\n",
    "        # 使用注意力权重对值张量进行加权求和，得到上下文向量，形状为 [batch_size, n_heads, len_q, d_v]\n",
    "        context = torch.matmul(attn, V)#[batch_size, n_heads, len_q, d_v]\n",
    "        return context, attn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb068257",
   "metadata": {},
   "source": [
    "## MultiHeadAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8127597e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        初始化 MultiHeadAttention 类的实例。\n",
    "        '''\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        # 线性变换，用于生成查询向量 Q 的权重矩阵，输出维度为 d_k * n_heads。\n",
    "        self.W_Q = nn.Linear(d_model, d_k * n_heads, bias=False)\n",
    "        # 线性变换，用于生成键向量 K 的权重矩阵，输出维度为 d_k * n_heads。\n",
    "        self.W_K = nn.Linear(d_model, d_k * n_heads, bias=False)\n",
    "        # 线性变换，用于生成值向量 V 的权重矩阵，输出维度为 d_v * n_heads。\n",
    "        self.W_V = nn.Linear(d_model, d_v * n_heads, bias=False)\n",
    "        # 线性变换，用于将多头注意力的输出映射回 d_model 维度。\n",
    "        self.fc = nn.Linear(n_heads * d_v, d_model, bias=False)\n",
    "\n",
    "    def forward(self, input_Q, input_K, input_V, attn_mask):\n",
    "        '''\n",
    "        前向传播函数，计算多头注意力机制。\n",
    "        参数:\n",
    "            input_Q (Tensor): 查询张量，形状为 [batch_size, len_q, d_model]。\n",
    "            input_K (Tensor): 键张量，形状为 [batch_size, len_k, d_model]。\n",
    "            input_V (Tensor): 值张量，形状为 [batch_size, len_v(=len_k), d_model]。\n",
    "            attn_mask (Tensor): 注意力掩码，形状为 [batch_size, seq_len, seq_len]。\n",
    "        返回:\n",
    "            output (Tensor): 多头注意力机制的输出，形状为 [batch_size, len_q, d_model]。\n",
    "            attn (Tensor): 注意力权重，形状为 [batch_size, n_heads, len_q, len_k]。\n",
    "        '''\n",
    "        residual, batch_size = input_Q, input_Q.size(0)\n",
    "        # 通过线性变换将输入映射到多头注意力的查询、键和值空间，并调整维度。\n",
    "        # 然后通过 view 和 transpose 操作，准备进行多头注意力计算。\n",
    "        #Q = self.W_Q(input_Q).view(batch_size, -1, n_heads, d_k).transpose(1, 2)  # Q: [batch_size, n_heads, len_q, d_k]\n",
    "        Q=self.W_Q(input_Q)\n",
    "        #print(Q.shape)\n",
    "        Q=Q.view(batch_size, -1, n_heads, d_k)#有多少个头就劈多少段\n",
    "        #print(Q.shape)\n",
    "        Q=Q.transpose(1, 2)#更换维度\n",
    "        #print(Q.shape)\n",
    "        \"\"\"\n",
    "        torch.Size([2, 5, 8])\n",
    "        torch.Size([2, 5, 2, 4])\n",
    "        torch.Size([2, 2, 5, 4])\n",
    "        \"\"\"\n",
    "        K = self.W_K(input_K).view(batch_size, -1, n_heads, d_k).transpose(1, 2)  # K: [batch_size, n_heads, len_k, d_k]\n",
    "        V = self.W_V(input_V).view(batch_size, -1, n_heads, d_v).transpose(1, 2)  # V: [batch_size, n_heads, len_v(=len_k), d_v]\n",
    "        # 将掩码调整为适应多头注意力的维度，并重复扩展到每一个头。\n",
    "        \n",
    "        #unsqueeze 是一个非常实用的函数，用于在指定位置增加一个维度\n",
    "        #.repeat(1, n_heads, 1, 1),在相应位置，重复n_heads 次\n",
    "        attn_mask = attn_mask.unsqueeze(1).repeat(1, n_heads, 1, 1)  # attn_mask: [batch_size, n_heads, seq_len, seq_len]\n",
    "        # 使用缩放点积注意力机制计算上下文向量和注意力权重。\n",
    "        context, attn = ScaledDotProductAttention()(Q, K, V, attn_mask)\n",
    "        # 将上下文向量从多头维度恢复为单一的注意力维度，并通过线性层映射回 d_model 维度。\n",
    "        context = context.transpose(1, 2).reshape(batch_size, -1, n_heads * d_v)  # context: [batch_size, len_q, n_heads * d_v]\n",
    "        # 使用全连接层将多头注意力的输出映射到原始的 d_model 维度。\n",
    "        output = self.fc(context)  # [batch_size, len_q, d_model]\n",
    "        # 将残差连接和层归一化应用于输出，并返回最终结果。\n",
    "        return nn.LayerNorm(d_model).to(device)(output + residual), attn"
   ]
  },
  {
   "cell_type": "raw",
   "id": "60c74cc3",
   "metadata": {},
   "source": [
    "\n",
    "# 确定设备\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 参数设定\n",
    "d_model = 8\n",
    "d_k = 4\n",
    "d_v = 4\n",
    "n_heads = 2\n",
    "batch_size = 2\n",
    "len_q = 5\n",
    "len_k = 5\n",
    "seq_len = 5\n",
    "\n",
    "# 创建 MultiHeadAttention 实例并移动到设备\n",
    "multihead_attention = MultiHeadAttention().to(device)\n",
    "\n",
    "# 随机生成输入数据并移动到设备\n",
    "input_Q = torch.randn(batch_size, len_q, d_model, device=device)\n",
    "input_K = torch.randn(batch_size, len_k, d_model, device=device)\n",
    "input_V = torch.randn(batch_size, len_k, d_model, device=device)\n",
    "\n",
    "# 创建随机注意力掩码并移动到设备\n",
    "attn_mask = torch.ones(batch_size, seq_len, seq_len, device=device)\n",
    "attn_mask = (attn_mask == 0)  # 将掩码中0的位置置为 True，其他位置为 False\n",
    "\n",
    "# 调用 forward 方法\n",
    "output, attn = multihead_attention(input_Q, input_K, input_V, attn_mask)\n",
    "\n",
    "# 打印输出结果的形状\n",
    "print(\"Output shape:\", output.shape)  # 应该是 [batch_size, len_q, d_model]\n",
    "print(\"Attention shape:\", attn.shape)  # 应该是 [batch_size, n_heads, len_q, len_k]\n",
    "\n",
    "# 打印输出结果\n",
    "print(\"Output:\")\n",
    "print(output)\n",
    "print(\"Attention weights:\")\n",
    "print(attn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565d3f10",
   "metadata": {},
   "source": [
    "## FeedForward Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f7216e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoswiseFeedForwardNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PoswiseFeedForwardNet, self).__init__()\n",
    "        # 定义前馈网络，包括两个线性层和一个ReLU激活函数\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(d_model, d_ff, bias=False),  # 第一个线性层，将输入从d_model维度映射到d_ff维度\n",
    "            nn.ReLU(),                            # ReLU激活函数，增加非线性\n",
    "            nn.Linear(d_ff, d_model, bias=False)  # 第二个线性层，将d_ff维度映射回d_model维度\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        '''\n",
    "        inputs: [batch_size, seq_len, d_model]\n",
    "        '''\n",
    "        residual = inputs  # 保存输入以便后续添加残差\n",
    "\n",
    "        output = self.fc(inputs)  # 将输入传入前馈网络 [batch_size, seq_len, d_model]\n",
    "\n",
    "        # 添加残差连接并进行层归一化\n",
    "        return nn.LayerNorm(d_model).to(device)(output + residual)  # [batch_size, seq_len, d_model]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17578800",
   "metadata": {},
   "source": [
    "## Encoder Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b8d88b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):#自注意力\n",
    "    def __init__(self):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        # 初始化多头自注意力机制\n",
    "        self.enc_self_attn = MultiHeadAttention()\n",
    "        # 初始化前馈网络\n",
    "        self.pos_ffn = PoswiseFeedForwardNet()\n",
    "    def forward(self, enc_inputs, enc_self_attn_mask):\n",
    "        '''\n",
    "        enc_inputs: [batch_size, src_len, d_model]\n",
    "        输入的形状是 [批次大小, 源序列长度, d_model]\n",
    "        enc_self_attn_mask: [batch_size, src_len, src_len]\n",
    "        自注意力掩码，形状为 [批次大小, 源序列长度, 源序列长度]\n",
    "        '''\n",
    "        # 通过多头自注意力机制处理输入\n",
    "        # enc_outputs: [batch_size, src_len, d_model]\n",
    "        # attn: [batch_size, n_heads, src_len, src_len]\n",
    "        enc_outputs, attn = self.enc_self_attn(enc_inputs, enc_inputs, enc_inputs, enc_self_attn_mask)\n",
    "        # 通过前馈网络处理自注意力的输出\n",
    "        enc_outputs = self.pos_ffn(enc_outputs)  # enc_outputs: [batch_size, src_len, d_model]\n",
    "        return enc_outputs, attn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b78263",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8cf964c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        # 词嵌入层，将词汇索引映射到d_model维度的向量\n",
    "        self.src_emb = nn.Embedding(src_vocab_size, d_model)\n",
    "        # 位置编码，用于加入位置信息\n",
    "        self.pos_emb = PositionalEncoding(d_model)\n",
    "        # 定义n_layers个EncoderLayer层\n",
    "        self.layers = nn.ModuleList([EncoderLayer() for _ in range(n_layers)])\n",
    "\n",
    "    def forward(self, enc_inputs):\n",
    "        '''\n",
    "        enc_inputs: [batch_size, src_len]\n",
    "        输入的形状是 [批次大小, 源序列长度]\n",
    "        '''\n",
    "        # 将输入索引转换为嵌入向量\n",
    "        enc_outputs = self.src_emb(enc_inputs)  # [batch_size, src_len, d_model]\n",
    "        # 添加位置编码，并恢复维度\n",
    "        enc_outputs = self.pos_emb(enc_outputs.transpose(0, 1)).transpose(0, 1)  # [batch_size, src_len, d_model]\n",
    "        # 生成自注意力的掩码\n",
    "        enc_self_attn_mask = get_attn_pad_mask(enc_inputs, enc_inputs)  # [batch_size, src_len, src_len]\n",
    "\n",
    "        enc_self_attns = []\n",
    "\n",
    "        # 逐层处理编码器层\n",
    "        for layer in self.layers:\n",
    "            # 处理每一层的输入，得到输出和注意力权重\n",
    "            enc_outputs, enc_self_attn = layer(enc_outputs, enc_self_attn_mask)\n",
    "            enc_self_attns.append(enc_self_attn)  # 保存每层的注意力权重\n",
    "        return enc_outputs, enc_self_attns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985f1ff4",
   "metadata": {},
   "source": [
    "## Decoder Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ea8e3556",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        # 初始化自注意力机制，用于处理目标序列的自注意力\n",
    "        self.dec_self_attn = MultiHeadAttention()\n",
    "        # 初始化编码器-解码器注意力机制，用于处理目标序列与源序列之间的注意力\n",
    "        self.dec_enc_attn = MultiHeadAttention()\n",
    "        # 初始化前馈网络\n",
    "        self.pos_ffn = PoswiseFeedForwardNet()\n",
    "\n",
    "    def forward(self, dec_inputs, enc_outputs, dec_self_attn_mask, dec_enc_attn_mask):\n",
    "        '''\n",
    "        dec_inputs: [batch_size, tgt_len, d_model]\n",
    "        解码器输入，形状为 [批次大小, 目标序列长度, d_model]\n",
    "        enc_outputs: [batch_size, src_len, d_model]\n",
    "        编码器的输出，形状为 [批次大小, 源序列长度, d_model]\n",
    "        dec_self_attn_mask: [batch_size, tgt_len, tgt_len]\n",
    "        解码器自注意力的掩码，形状为 [批次大小, 目标序列长度, 目标序列长度]\n",
    "        dec_enc_attn_mask: [batch_size, tgt_len, src_len]\n",
    "        解码器-编码器注意力的掩码，形状为 [批次大小, 目标序列长度, 源序列长度]\n",
    "        '''\n",
    "        # 通过解码器的自注意力机制处理输入\n",
    "        # dec_outputs: [batch_size, tgt_len, d_model]\n",
    "        # dec_self_attn: [batch_size, n_heads, tgt_len, tgt_len]\n",
    "        dec_outputs, dec_self_attn = self.dec_self_attn(dec_inputs, dec_inputs, dec_inputs, dec_self_attn_mask)\n",
    "\n",
    "        # 通过解码器的编码器-解码器注意力机制处理输出\n",
    "        # dec_outputs: [batch_size, tgt_len, d_model]\n",
    "        # dec_enc_attn: [batch_size, n_heads, tgt_len, src_len]\n",
    "        dec_outputs, dec_enc_attn = self.dec_enc_attn(dec_outputs, enc_outputs, enc_outputs, dec_enc_attn_mask)\n",
    "\n",
    "        # 通过前馈网络处理解码器的输出\n",
    "        dec_outputs = self.pos_ffn(dec_outputs)  # [batch_size, tgt_len, d_model]\n",
    "\n",
    "        # 返回处理后的输出以及注意力权重\n",
    "        return dec_outputs, dec_self_attn, dec_enc_attn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c6884f",
   "metadata": {},
   "source": [
    "## Decoder\n",
    "\n",
    "\n",
    "`torch.gt` 是 PyTorch 中的一个函数，用于执行大于比较操作。具体来说，`torch.gt(input, other)` 会逐元素比较 `input` 和 `other`，如果 `input` 中的元素大于 `other` 中对应的元素，则返回 `True`（或者在布尔张量中是 `1`），否则返回 `False`（或者是 `0`）。这个操作是逐元素的，即元素级的比较。\n",
    "\n",
    "在你的代码中：\n",
    "\n",
    "```python\n",
    "dec_self_attn_mask = torch.gt((dec_self_attn_pad_mask + dec_self_attn_subsequence_mask), 0).cuda()\n",
    "```\n",
    "\n",
    "### 代码解析\n",
    "\n",
    "1. **`dec_self_attn_pad_mask`** 和 **`dec_self_attn_subsequence_mask`** 是两个掩码张量：\n",
    "   - `dec_self_attn_pad_mask` 用于掩盖填充部分（padding）。\n",
    "   - `dec_self_attn_subsequence_mask` 用于掩盖目标序列中未来的部分（即防止信息泄露）。\n",
    "\n",
    "2. **加法操作**：`dec_self_attn_pad_mask + dec_self_attn_subsequence_mask` 将两个掩码相加。这种加法通常会得到一个新张量，其中填充值和未来信息的掩码位置的和可能是 `0` 或者大于 `0` 的值。具体取决于原始掩码的值。\n",
    "\n",
    "3. **`torch.gt(..., 0)`**：\n",
    "   - `torch.gt` 将新张量与 `0` 进行比较，得到一个布尔张量，其中的元素如果大于 `0`，则该位置为 `True`（在布尔张量中表示为 `1`），否则为 `False`（表示为 `0`）。\n",
    "   - 这个操作会将掩码张量的元素值大于 `0` 的位置标记为 `True`，否则标记为 `False`。它有效地合并了填充掩码和子序列掩码，形成一个最终的自注意力掩码。\n",
    "\n",
    "4. **`.cuda()`**：将生成的布尔张量转移到 GPU 上，以便进行 GPU 加速的计算。\n",
    "\n",
    "### 总结\n",
    "\n",
    "`torch.gt` 的作用是对张量的每个元素进行大于比较操作，并返回一个布尔张量。在你的代码中，它用于生成最终的自注意力掩码，掩码中 `0` 位置的元素会被标记为 `False`（或者 `0`），大于 `0` 的元素会被标记为 `True`（或者 `1`）。这对于掩盖不需要注意的位置（如填充部分和未来部分）是非常重要的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dcb8d54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "        # 目标语言的词嵌入层，将目标词汇索引映射到d_model维度的向量\n",
    "        self.tgt_emb = nn.Embedding(tgt_vocab_size, d_model)\n",
    "        # 位置编码，用于为目标序列添加位置信息\n",
    "        self.pos_emb = PositionalEncoding(d_model)\n",
    "        # 定义n_layers个DecoderLayer层\n",
    "        self.layers = nn.ModuleList([DecoderLayer() for _ in range(n_layers)])\n",
    "\n",
    "    def forward(self, dec_inputs, enc_inputs, enc_outputs):\n",
    "        '''\n",
    "        dec_inputs: [batch_size, tgt_len]\n",
    "        解码器的输入，形状为 [批次大小, 目标序列长度]\n",
    "\n",
    "        enc_inputs: [batch_size, src_len]\n",
    "        编码器的输入，形状为 [批次大小, 源序列长度]\n",
    "\n",
    "        enc_outputs: [batch_size, src_len, d_model]\n",
    "        编码器的输出，形状为 [批次大小, 源序列长度, d_model]\n",
    "        '''\n",
    "\n",
    "        # 将解码器输入转换为嵌入向量\n",
    "        dec_outputs = self.tgt_emb(dec_inputs)  # [batch_size, tgt_len, d_model]\n",
    "        # 添加位置编码\n",
    "        dec_outputs = self.pos_emb(dec_outputs.transpose(0, 1)).transpose(0, 1).to(device)  # [batch_size, tgt_len, d_model]\n",
    "        # 生成自注意力的填充掩码\n",
    "        dec_self_attn_pad_mask = get_attn_pad_mask(dec_inputs, dec_inputs).to(device)  # [batch_size, tgt_len, tgt_len]\n",
    "        # 生成自注意力的子序列掩码\n",
    "        dec_self_attn_subsequence_mask = get_attn_subsequence_mask(dec_inputs).to(device)  # [batch_size, tgt_len, tgt_len]\n",
    "        # 合并掩码，得到最终的自注意力掩码\n",
    "        dec_self_attn_mask = torch.gt((dec_self_attn_pad_mask + dec_self_attn_subsequence_mask), 0).to(device)  # [batch_size, tgt_len, tgt_len]\n",
    "\n",
    "        # 生成解码器-编码器注意力的掩码\n",
    "        dec_enc_attn_mask = get_attn_pad_mask(dec_inputs, enc_inputs)  # [batch_size, tgt_len, src_len]\n",
    "\n",
    "        # 初始化存储注意力权重的列表\n",
    "        dec_self_attns, dec_enc_attns = [], []\n",
    "\n",
    "        # 逐层处理解码器层\n",
    "        for layer in self.layers:\n",
    "            # 处理每层的输入，得到输出和注意力权重\n",
    "            # dec_outputs: [batch_size, tgt_len, d_model]\n",
    "            # dec_self_attn: [batch_size, n_heads, tgt_len, tgt_len]\n",
    "            # dec_enc_attn: [batch_size, n_heads, tgt_len, src_len]\n",
    "            dec_outputs, dec_self_attn, dec_enc_attn = layer(dec_outputs, enc_outputs, dec_self_attn_mask, dec_enc_attn_mask)\n",
    "\n",
    "            # 保存每层的自注意力和编码器-解码器注意力权重\n",
    "            dec_self_attns.append(dec_self_attn)\n",
    "            dec_enc_attns.append(dec_enc_attn)\n",
    "\n",
    "        # 返回处理后的解码器输出以及所有层的自注意力和编码器-解码器注意力权重\n",
    "        return dec_outputs, dec_self_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dca91c5",
   "metadata": {},
   "source": [
    "## Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "be7d3eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Transformer, self).__init__()\n",
    "        # 初始化编码器，将数据传递到GPU上\n",
    "        self.encoder = Encoder().to(device)\n",
    "        # 初始化解码器，将数据传递到GPU上\n",
    "        self.decoder = Decoder().to(device)\n",
    "        # 初始化线性投影层，用于将解码器的输出映射到目标词汇表的大小\n",
    "        self.projection = nn.Linear(d_model, tgt_vocab_size, bias=False).to(device)\n",
    "\n",
    "    def forward(self, enc_inputs, dec_inputs):\n",
    "        '''\n",
    "        enc_inputs: [batch_size, src_len]\n",
    "        编码器的输入，形状为 [批次大小, 源序列长度]\n",
    "\n",
    "        dec_inputs: [batch_size, tgt_len]\n",
    "        解码器的输入，形状为 [批次大小, 目标序列长度]\n",
    "        '''\n",
    "        # 通过编码器处理输入，得到编码器的输出和自注意力权重\n",
    "        # enc_outputs: [batch_size, src_len, d_model]\n",
    "        # enc_self_attns: [n_layers, batch_size, n_heads, src_len, src_len]\n",
    "        enc_outputs, enc_self_attns = self.encoder(enc_inputs)\n",
    "\n",
    "        # 通过解码器处理输入，得到解码器的输出、自注意力权重和编码器-解码器注意力权重\n",
    "        # dec_outputs: [batch_size, tgt_len, d_model]\n",
    "        # dec_self_attns: [n_layers, batch_size, n_heads, tgt_len, tgt_len]\n",
    "        # dec_enc_attns: [n_layers, batch_size, n_heads, tgt_len, src_len]\n",
    "        dec_outputs, dec_self_attns, dec_enc_attns = self.decoder(dec_inputs, enc_inputs, enc_outputs)\n",
    "\n",
    "        # 通过线性层将解码器输出映射到目标词汇表的大小\n",
    "        # dec_logits: [batch_size, tgt_len, tgt_vocab_size]\n",
    "        dec_logits = self.projection(dec_outputs)\n",
    "\n",
    "        # 将输出形状调整为 [batch_size * tgt_len, tgt_vocab_size] 以适应交叉熵损失\n",
    "        return dec_logits.view(-1, dec_logits.size(-1)), enc_self_attns, dec_self_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a4352ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer().to(device)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-3, momentum=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "786d9553",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()  # Set the model to training mode\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch_idx, (src, tgt) in enumerate(dataloader):\n",
    "        src = src.to(device)\n",
    "        tgt = tgt.to(device)\n",
    "        \n",
    "        # Shift target tensors to the right to create input and target for the model\n",
    "        tgt_input = tgt[:, :-1]\n",
    "        tgt_output = tgt[:, 1:]\n",
    "        \n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        output, _, _, _ = model(src, tgt_input)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = criterion(output.view(-1, output.size(-1)), tgt_output.contiguous().view(-1))\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "#         if (batch_idx + 1) % 10 == 0:  # Print every 10 batches\n",
    "#             print(f'Batch {batch_idx + 1}, Loss: {loss.item()}')\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    print(f'Average Loss for Epoch: {avg_loss}')\n",
    "\n",
    "def train(model, dataloader, criterion, optimizer, device, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        print(f'Epoch {epoch + 1}/{epochs}')\n",
    "        train_epoch(model, dataloader, criterion, optimizer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "86ba92a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "Average Loss for Epoch: 0.00014083076748647728\n",
      "Epoch 2/50\n",
      "Average Loss for Epoch: 0.0001390899262332823\n",
      "Epoch 3/50\n",
      "Average Loss for Epoch: 0.0001545747625641525\n",
      "Epoch 4/50\n",
      "Average Loss for Epoch: 0.00014254886409617029\n",
      "Epoch 5/50\n",
      "Average Loss for Epoch: 0.00014406766349566168\n",
      "Epoch 6/50\n",
      "Average Loss for Epoch: 0.00013651763947564177\n",
      "Epoch 7/50\n",
      "Average Loss for Epoch: 0.0001514321098511573\n",
      "Epoch 8/50\n",
      "Average Loss for Epoch: 0.00015020890059531667\n",
      "Epoch 9/50\n",
      "Average Loss for Epoch: 0.0001485766719270032\n",
      "Epoch 10/50\n",
      "Average Loss for Epoch: 0.00013409493258222937\n",
      "Epoch 11/50\n",
      "Average Loss for Epoch: 0.00014275765934144147\n",
      "Epoch 12/50\n",
      "Average Loss for Epoch: 0.00014102914501563647\n",
      "Epoch 13/50\n",
      "Average Loss for Epoch: 0.00014063341004657559\n",
      "Epoch 14/50\n",
      "Average Loss for Epoch: 0.0001320280112850014\n",
      "Epoch 15/50\n",
      "Average Loss for Epoch: 0.00013536174446926452\n",
      "Epoch 16/50\n",
      "Average Loss for Epoch: 0.00013410299143288285\n",
      "Epoch 17/50\n",
      "Average Loss for Epoch: 0.00013190246536396444\n",
      "Epoch 18/50\n",
      "Average Loss for Epoch: 0.00013875883669243195\n",
      "Epoch 19/50\n",
      "Average Loss for Epoch: 0.00014016888162586837\n",
      "Epoch 20/50\n",
      "Average Loss for Epoch: 0.00013188878510845826\n",
      "Epoch 21/50\n",
      "Average Loss for Epoch: 0.00012295210981392302\n",
      "Epoch 22/50\n",
      "Average Loss for Epoch: 0.00012587841483764351\n",
      "Epoch 23/50\n",
      "Average Loss for Epoch: 0.00013167174693080598\n",
      "Epoch 24/50\n",
      "Average Loss for Epoch: 0.00013420051327557304\n",
      "Epoch 25/50\n",
      "Average Loss for Epoch: 0.0001357286200800445\n",
      "Epoch 26/50\n",
      "Average Loss for Epoch: 0.00012636692335945554\n",
      "Epoch 27/50\n",
      "Average Loss for Epoch: 0.00012745373096549882\n",
      "Epoch 28/50\n",
      "Average Loss for Epoch: 0.00012064552938682028\n",
      "Epoch 29/50\n",
      "Average Loss for Epoch: 0.00013254564692033455\n",
      "Epoch 30/50\n",
      "Average Loss for Epoch: 0.00012316752035985702\n",
      "Epoch 31/50\n",
      "Average Loss for Epoch: 0.00012836097303079442\n",
      "Epoch 32/50\n",
      "Average Loss for Epoch: 0.00012722971951006912\n",
      "Epoch 33/50\n",
      "Average Loss for Epoch: 0.00013163249532226472\n",
      "Epoch 34/50\n",
      "Average Loss for Epoch: 0.00012306305761740078\n",
      "Epoch 35/50\n",
      "Average Loss for Epoch: 0.00013890155387343838\n",
      "Epoch 36/50\n",
      "Average Loss for Epoch: 0.0001253323549462948\n",
      "Epoch 37/50\n",
      "Average Loss for Epoch: 0.00012755795250996016\n",
      "Epoch 38/50\n",
      "Average Loss for Epoch: 0.00012342309928499163\n",
      "Epoch 39/50\n",
      "Average Loss for Epoch: 0.00012147043526056223\n",
      "Epoch 40/50\n",
      "Average Loss for Epoch: 0.00011692913467413746\n",
      "Epoch 41/50\n",
      "Average Loss for Epoch: 0.00011540536579559557\n",
      "Epoch 42/50\n",
      "Average Loss for Epoch: 0.0001271199718757998\n",
      "Epoch 43/50\n",
      "Average Loss for Epoch: 0.0001260018805623986\n",
      "Epoch 44/50\n",
      "Average Loss for Epoch: 0.0001179773396870587\n",
      "Epoch 45/50\n",
      "Average Loss for Epoch: 0.00011977472895523533\n",
      "Epoch 46/50\n",
      "Average Loss for Epoch: 0.00011352968795108609\n",
      "Epoch 47/50\n",
      "Average Loss for Epoch: 0.00012055048136971891\n",
      "Epoch 48/50\n",
      "Average Loss for Epoch: 0.00011555088058230467\n",
      "Epoch 49/50\n",
      "Average Loss for Epoch: 0.00011183970818819943\n",
      "Epoch 50/50\n",
      "Average Loss for Epoch: 0.00011703943819156848\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "train(model, dataloader, criterion, optimizer, device, epochs)#训练\n",
    "# 在训练完成后保存模型\n",
    "# 保存模型的状态字典\n",
    "torch.save(model.state_dict(), './pth/Transformer_EN2CHN.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c0914e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentence(model, sentence, src_vocab, tgt_vocab, device, max_len_tgt=50):#贪婪\n",
    "    \"\"\"\n",
    "    使用模型生成目标语言的翻译句子。\n",
    "\n",
    "    参数:\n",
    "        model (nn.Module): 训练好的翻译模型。\n",
    "        sentence (str): 输入的源语言句子。\n",
    "        src_vocab (dict): 源语言的词汇表，将词汇映射到索引。\n",
    "        tgt_vocab (dict): 目标语言的词汇表，将词汇映射到索引。\n",
    "        device (torch.device): 设备类型（CPU 或 GPU）。\n",
    "        max_len_tgt (int): 目标语言序列的最大长度。\n",
    "\n",
    "    返回:\n",
    "        str: 目标语言的翻译句子。\n",
    "    \"\"\"\n",
    "    model.eval()  # 将模型设置为评估模式，这会影响到像 dropout 和 batch norm 之类的层\n",
    "    \n",
    "    # 预处理源语言句子\n",
    "    sentence = sentence.lower()  # 转换为小写\n",
    "    sentence = sentence[:-1] + \" \" + sentence[-1]  # 在句子的最后一个标点符号前插入空格\n",
    "\n",
    "    # 将源语言句子分词并转换为索引\n",
    "    src_indices = sentence.split()  # 将句子分割成单词列表\n",
    "    src_indices = [src_vocab[token] for token in src_indices if token in src_vocab]  # 将单词转换为索引\n",
    "    src_tensor = torch.tensor(src_indices, dtype=torch.long).unsqueeze(0).to(device)  # 转换为张量并添加批处理维度\n",
    "\n",
    "    # 初始化目标语言序列，开始标记 <sos> （'<start>': 1）\n",
    "    tgt_indices = [tgt_vocab['<start>']]  # 初始化目标序列\n",
    "    tgt_tensor = torch.tensor(tgt_indices, dtype=torch.long).unsqueeze(0).to(device)  # 转换为张量并添加批处理维度\n",
    "\n",
    "    with torch.no_grad():  # 在预测过程中禁用梯度计算，以节省内存和计算\n",
    "        for _ in range(max_len_tgt):  # 生成目标序列的最大长度\n",
    "            # 模型前向传播\n",
    "            output, _, _, _ = model(src_tensor, tgt_tensor)  # 获取模型的输出\n",
    "            \n",
    "            # 确保输出形状为 [batch_size, seq_len, vocab_size]\n",
    "            output_word = output.squeeze(0)  # 去掉批处理维度，得到 [seq_len, vocab_size]\n",
    "            last_output_word = output_word[-1]  # 取最后一个时间步的输出 [vocab_size]\n",
    "\n",
    "            # 选择下一个词汇\n",
    "            next_token = torch.argmax(last_output_word, dim=-1).item()  # 选择概率最高的词汇\n",
    "            \n",
    "            if next_token == tgt_vocab['<end>']:  # 如果生成了结束标记，则停止生成\n",
    "                break\n",
    "\n",
    "            tgt_indices.append(next_token)  # 将生成的词汇添加到目标序列中\n",
    "            tgt_tensor = torch.tensor(tgt_indices, dtype=torch.long).unsqueeze(0).to(device)  # 更新目标张量\n",
    "\n",
    "    # 将索引转换回单词\n",
    "    inv_tgt_vocab = {idx: word for word, idx in tgt_vocab.items()}  # 创建索引到词汇的反向词汇表\n",
    "    translated_sentence = ''.join(inv_tgt_vocab.get(idx, '<unk>') for idx in tgt_indices[2:])  # 将索引转换为单词并拼接成句子\n",
    "\n",
    "    return translated_sentence  # 返回生成的翻译句子，去除前面可能的多余部分"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36956b30",
   "metadata": {},
   "source": [
    "## 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c14af6b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原 句：Do you have any plans for tonight? \n",
      "翻 译：你今天晚上有什么计划吗？\n"
     ]
    }
   ],
   "source": [
    "# 1. 导入之前的分词表\n",
    "with open('./vocab/Transformer_english_vocab.pkl', 'rb') as f:\n",
    "    english_vocab = pickle.load(f)\n",
    "with open('./vocab/Transformer_chinese_vocab.pkl', 'rb') as f:\n",
    "    chinese_vocab = pickle.load(f)\n",
    "#2. 导入模型\n",
    "model = Transformer().to(device)\n",
    "model.load_state_dict(torch.load('./pth/Transformer_EN2CHN.pth'))\n",
    "#3. 定义设备\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#4. 开始测试\n",
    "sentence = \"Do you have any plans for tonight?\"\n",
    "translated_sentence = predict_sentence(model, sentence, english_vocab, chinese_vocab, device)\n",
    "print(f\"原 句：{sentence} \\n翻 译：{translated_sentence}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1261ff3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
